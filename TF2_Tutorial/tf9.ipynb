{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqH1BDgoPX4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RNN poem generatior"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9emku4HPx-X",
        "colab_type": "code",
        "outputId": "3c36dffa-4168-4cfe-9647-ccde3feeba96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN-Ly2NUQIKr",
        "colab_type": "code",
        "outputId": "946d9031-8eec-4ee6-de5c-232486f7eda1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# one letter at a time, we run multiple times and the play is generated.\n",
        "\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "path_to_file"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/shakespeare.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6wwH1qjRMBX",
        "colab_type": "code",
        "outputId": "1382c4cd-5e87-40f8-89e6-e19a58415335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print(len(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVVdPe9MRkMC",
        "colab_type": "code",
        "outputId": "d3048b65-577a-4619-dbdb-e09790e99de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Enw9igKRu1Q",
        "colab_type": "code",
        "outputId": "c1280edc-648e-47f2-8c5e-0313e86e8e63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# preprocessing , encoding to integers.\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "len(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky2VG8MRSTn2",
        "colab_type": "code",
        "outputId": "9ecefe6b-f869-4f96-b7f4-56e7ef6a8d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# create a dict of the vocab and their representetive number.\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "len(char2idx)\n",
        "idx2char = np.array(vocab)\n",
        "idx2char\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int = text_to_int(text)\n",
        "text_as_int"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 47, 56, ..., 45,  8,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpI6ZVkuW8dO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr = text_to_int('Speak, speak.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8byPMbejWoKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def int_to_text(arr):\n",
        "  try:\n",
        "    arr = arr.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx2char[arr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-McdcjaDXEwA",
        "colab_type": "code",
        "outputId": "e1d93c93-6dd7-46b6-cfa3-40af447e1bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "txt = int_to_text(arr)\n",
        "txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Speak, speak.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "763IAm8wW6mW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6cvj3WETUh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shift words by one character to create training samples\n",
        "\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text) // (seq_length + 1)\n",
        "examples_per_epoch\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7aFsQ_KUgpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "# lengths of 101 are picked"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2KgF_ZAVlLW",
        "colab_type": "code",
        "outputId": "94d02019-5910-4752-bb26-374d91767c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sequences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: (101,), types: tf.int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZxf1GZdVC6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1] # HELL\n",
        "  target_text = chunk[1:] # ELLO\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQoqct4YVzAq",
        "colab_type": "code",
        "outputId": "9f31f8a6-2d9b-4e79-9ea9-b471427a3224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5tzgQVvV2_Y",
        "colab_type": "code",
        "outputId": "41964cd9-f793-4093-d473-42e9f4f72eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "for x, y in dataset.take(2):\n",
        "  print(int_to_text(x))\n",
        "  print(int_to_text(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z696TpXBYykP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL305MduZUvy",
        "colab_type": "code",
        "outputId": "911cb923-632a-492b-e89a-8abd58013812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                                         batch_input_shape=[batch_size, None]),\n",
        "                               tf.keras.layers.LSTM(rnn_units,\n",
        "                                                    return_sequences=True,\n",
        "                                                    stateful=True,\n",
        "                                                    recurrent_initializer='glorot_uniform'),\n",
        "                               tf.keras.layers.Dense(vocab_size) # probability for the next character\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRrV4sPlaZdY",
        "colab_type": "code",
        "outputId": "ccc53085-44c3-48b0-836d-6e44c0447cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcP3MDa9buri",
        "colab_type": "code",
        "outputId": "aa187e49-02bd-48ab-b0af-ef42b9e23895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[-0.00082702  0.00200509 -0.00070652 ...  0.00045198 -0.00115732\n",
            "    0.00677575]\n",
            "  [-0.00279657  0.00202235  0.00024598 ... -0.00221867  0.0017723\n",
            "    0.00596637]\n",
            "  [-0.00454159  0.00581424 -0.00274956 ...  0.00158515  0.00209609\n",
            "    0.01188151]\n",
            "  ...\n",
            "  [-0.01290994  0.01519141 -0.00305946 ...  0.00227756 -0.00248681\n",
            "    0.00629189]\n",
            "  [-0.01630002  0.01841058 -0.00321782 ...  0.0003033  -0.00040643\n",
            "    0.00392205]\n",
            "  [-0.01577934  0.01321387 -0.00107076 ...  0.00043978  0.00105818\n",
            "    0.00192802]]\n",
            "\n",
            " [[-0.00169298 -0.00118001 -0.00030001 ... -0.0038305   0.00085708\n",
            "    0.00166719]\n",
            "  [ 0.00277293  0.00186329  0.00014444 ...  0.00173474 -0.00104293\n",
            "    0.00529115]\n",
            "  [ 0.00455769 -0.00424499 -0.00598387 ...  0.00434343  0.00631629\n",
            "    0.00421247]\n",
            "  ...\n",
            "  [-0.00432417  0.01549965 -0.01277741 ...  0.00461921 -0.00503589\n",
            "    0.00742809]\n",
            "  [-0.00141547  0.01122486 -0.00647786 ... -0.00149425 -0.00345704\n",
            "    0.00674018]\n",
            "  [-0.001207    0.01106475 -0.00108161 ... -0.0031883  -0.00700224\n",
            "    0.00844855]]\n",
            "\n",
            " [[ 0.00382267  0.00233494  0.00187868 ...  0.00152618  0.00545148\n",
            "   -0.00079607]\n",
            "  [ 0.00077066  0.00496278 -0.0001486  ...  0.00534566  0.0064742\n",
            "    0.0068497 ]\n",
            "  [-0.00616371  0.00113734 -0.01204737 ...  0.00701999  0.00593324\n",
            "    0.00403049]\n",
            "  ...\n",
            "  [-0.00478605  0.00426496 -0.00481259 ... -0.00018919  0.00357466\n",
            "    0.01442006]\n",
            "  [-0.00613713  0.00112107 -0.00403842 ... -0.00180962  0.0050725\n",
            "    0.00768014]\n",
            "  [-0.00366278 -0.00110368 -0.00123999 ... -0.00442486  0.00376777\n",
            "    0.00543418]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.00217276  0.00428776 -0.00165305 ...  0.00325419  0.0017177\n",
            "    0.00713585]\n",
            "  [-0.00245527 -0.00117516 -0.0007118  ...  0.00124736  0.00382671\n",
            "    0.0071996 ]\n",
            "  [-0.00322839  0.0005336  -0.00035439 ...  0.00200971  0.00290972\n",
            "    0.01218604]\n",
            "  ...\n",
            "  [-0.0078927   0.01162508 -0.00758576 ... -0.00770906 -0.00519691\n",
            "    0.00261412]\n",
            "  [-0.00897126  0.01362823 -0.00642677 ... -0.00381232 -0.00041194\n",
            "    0.00720019]\n",
            "  [-0.00807859  0.01223352 -0.00032668 ... -0.00412425 -0.00288708\n",
            "    0.00631067]]\n",
            "\n",
            " [[ 0.00254614  0.00300697 -0.00598642 ...  0.00549794 -0.001001\n",
            "   -0.00095121]\n",
            "  [ 0.00327518  0.00037154 -0.00121234 ...  0.00050011 -0.0010407\n",
            "   -0.00035766]\n",
            "  [ 0.00081011  0.00444307 -0.002462   ...  0.00312879  0.00108123\n",
            "    0.00716342]\n",
            "  ...\n",
            "  [ 0.00587385  0.00371206 -0.00049534 ...  0.00636004  0.00095099\n",
            "    0.01015489]\n",
            "  [ 0.00452008  0.000452   -0.00461053 ...  0.00924293 -0.00220876\n",
            "    0.00813296]\n",
            "  [ 0.00311086 -0.00116484 -0.00618429 ...  0.0020807  -0.00267614\n",
            "    0.00283964]]\n",
            "\n",
            " [[-0.00544454  0.00637264 -0.0016949  ... -0.00210352  0.0009698\n",
            "   -0.00135648]\n",
            "  [-0.00525516  0.01452535 -0.00330667 ... -0.00180196 -0.00395229\n",
            "   -0.00693403]\n",
            "  [-0.00568785  0.0138805  -0.00249571 ... -0.00110016 -0.00507162\n",
            "    0.00149206]\n",
            "  ...\n",
            "  [-0.00736563  0.00898184 -0.00550008 ...  0.00424075 -0.00363291\n",
            "    0.0154281 ]\n",
            "  [-0.00663936  0.00820661 -0.00091479 ...  0.00203249 -0.006484\n",
            "    0.01305174]\n",
            "  [-0.00455667  0.00443864  0.00107878 ... -0.00108557 -0.00304825\n",
            "    0.01022193]]], shape=(64, 100, 65), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyEN6A2pcQVw",
        "colab_type": "code",
        "outputId": "6011b00e-fdae-4385-abb2-cf829c554eb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "pred = example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)\n",
        "# for every character there is a prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[-0.00082702  0.00200509 -0.00070652 ...  0.00045198 -0.00115732\n",
            "   0.00677575]\n",
            " [-0.00279657  0.00202235  0.00024598 ... -0.00221867  0.0017723\n",
            "   0.00596637]\n",
            " [-0.00454159  0.00581424 -0.00274956 ...  0.00158515  0.00209609\n",
            "   0.01188151]\n",
            " ...\n",
            " [-0.01290994  0.01519141 -0.00305946 ...  0.00227756 -0.00248681\n",
            "   0.00629189]\n",
            " [-0.01630002  0.01841058 -0.00321782 ...  0.0003033  -0.00040643\n",
            "   0.00392205]\n",
            " [-0.01577934  0.01321387 -0.00107076 ...  0.00043978  0.00105818\n",
            "   0.00192802]], shape=(100, 65), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0G5PXfmctNb",
        "colab_type": "code",
        "outputId": "d5c51654-e3e8-4c7f-b029-b3ba6d6e6ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "time_pred = pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[-0.00082702  0.00200509 -0.00070652 -0.00134229  0.00200452  0.00123997\n",
            " -0.00380347  0.0005456   0.00391901 -0.00252769 -0.00254544 -0.0037947\n",
            " -0.0027279   0.00414711  0.0009107  -0.00168401  0.00090094 -0.00163784\n",
            "  0.00205354  0.00309464 -0.00372314  0.00067793  0.0016525  -0.00930487\n",
            "  0.00256955 -0.00215466 -0.00245249  0.00246958 -0.00426134  0.00099242\n",
            " -0.00142198 -0.00233984  0.00012841 -0.00495532 -0.0042601   0.00110647\n",
            " -0.00562175 -0.00417898 -0.00545525  0.00144647 -0.003159   -0.00379408\n",
            " -0.00347164  0.00324371 -0.00047511  0.00023025 -0.0011632  -0.00147226\n",
            " -0.00417836 -0.00218375  0.00068305 -0.00155582  0.0066727  -0.00146308\n",
            " -0.0044701  -0.00496119 -0.00097079 -0.00047026 -0.00419251  0.00628326\n",
            " -0.00132167 -0.0005822   0.00045198 -0.00115732  0.00677575], shape=(65,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkqTIpuyc3zH",
        "colab_type": "code",
        "outputId": "959dc5ae-6f42-446b-ca51-5f960c8c1ae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
        "print(sampled_indices)\n",
        "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
        "print(sampled_indices)\n",
        "predicted_chars = int_to_text(sampled_indices)\n",
        "\n",
        "print(predicted_chars)\n",
        "print(len(predicted_chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[40]\n",
            " [64]\n",
            " [63]\n",
            " [64]\n",
            " [63]\n",
            " [ 5]\n",
            " [26]\n",
            " [62]\n",
            " [41]\n",
            " [59]\n",
            " [ 6]\n",
            " [ 5]\n",
            " [17]\n",
            " [12]\n",
            " [42]\n",
            " [37]\n",
            " [ 5]\n",
            " [20]\n",
            " [ 7]\n",
            " [44]\n",
            " [ 2]\n",
            " [26]\n",
            " [54]\n",
            " [25]\n",
            " [55]\n",
            " [35]\n",
            " [64]\n",
            " [20]\n",
            " [30]\n",
            " [50]\n",
            " [58]\n",
            " [ 3]\n",
            " [17]\n",
            " [23]\n",
            " [20]\n",
            " [38]\n",
            " [26]\n",
            " [59]\n",
            " [20]\n",
            " [62]\n",
            " [45]\n",
            " [17]\n",
            " [38]\n",
            " [41]\n",
            " [63]\n",
            " [33]\n",
            " [47]\n",
            " [31]\n",
            " [22]\n",
            " [16]\n",
            " [ 6]\n",
            " [61]\n",
            " [40]\n",
            " [19]\n",
            " [44]\n",
            " [ 8]\n",
            " [33]\n",
            " [13]\n",
            " [ 1]\n",
            " [19]\n",
            " [12]\n",
            " [52]\n",
            " [18]\n",
            " [42]\n",
            " [45]\n",
            " [45]\n",
            " [32]\n",
            " [30]\n",
            " [10]\n",
            " [63]\n",
            " [18]\n",
            " [27]\n",
            " [38]\n",
            " [52]\n",
            " [ 4]\n",
            " [ 7]\n",
            " [56]\n",
            " [22]\n",
            " [10]\n",
            " [10]\n",
            " [47]\n",
            " [48]\n",
            " [27]\n",
            " [26]\n",
            " [13]\n",
            " [48]\n",
            " [14]\n",
            " [59]\n",
            " [33]\n",
            " [52]\n",
            " [14]\n",
            " [22]\n",
            " [28]\n",
            " [11]\n",
            " [62]\n",
            " [32]\n",
            " [32]\n",
            " [48]\n",
            " [21]\n",
            " [52]], shape=(100, 1), dtype=int64)\n",
            "[40 64 63 64 63  5 26 62 41 59  6  5 17 12 42 37  5 20  7 44  2 26 54 25\n",
            " 55 35 64 20 30 50 58  3 17 23 20 38 26 59 20 62 45 17 38 41 63 33 47 31\n",
            " 22 16  6 61 40 19 44  8 33 13  1 19 12 52 18 42 45 45 32 30 10 63 18 27\n",
            " 38 52  4  7 56 22 10 10 47 48 27 26 13 48 14 59 33 52 14 22 28 11 62 32\n",
            " 32 48 21 52]\n",
            "bzyzy'Nxcu,'E?dY'H-f!NpMqWzHRlt$EKHZNuHxgEZcyUiSJD,wbGf.UA G?nFdggTR:yFOZn&-rJ::ijONAjBuUnBJP;xTTjIn\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymEXEA8UeAuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e04vCzmeeY9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7BIJhmCeijx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxVW9VIpfhog",
        "colab_type": "code",
        "outputId": "c664c69c-4881-4d2c-f9b5-2662cd16a86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(data, epochs=40, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "172/172 [==============================] - 15s 87ms/step - loss: 2.6132\n",
            "Epoch 2/40\n",
            "172/172 [==============================] - 15s 86ms/step - loss: 1.9304\n",
            "Epoch 3/40\n",
            "172/172 [==============================] - 15s 87ms/step - loss: 1.6832\n",
            "Epoch 4/40\n",
            "172/172 [==============================] - 15s 87ms/step - loss: 1.5384\n",
            "Epoch 5/40\n",
            "172/172 [==============================] - 15s 88ms/step - loss: 1.4473\n",
            "Epoch 6/40\n",
            "172/172 [==============================] - 15s 88ms/step - loss: 1.3859\n",
            "Epoch 7/40\n",
            "172/172 [==============================] - 15s 88ms/step - loss: 1.3384\n",
            "Epoch 8/40\n",
            "172/172 [==============================] - 15s 89ms/step - loss: 1.2981\n",
            "Epoch 9/40\n",
            "172/172 [==============================] - 15s 89ms/step - loss: 1.2629\n",
            "Epoch 10/40\n",
            "172/172 [==============================] - 15s 89ms/step - loss: 1.2282\n",
            "Epoch 11/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 1.1939\n",
            "Epoch 12/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 1.1606\n",
            "Epoch 13/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 1.1246\n",
            "Epoch 14/40\n",
            "172/172 [==============================] - 15s 89ms/step - loss: 1.0888\n",
            "Epoch 15/40\n",
            "172/172 [==============================] - 15s 89ms/step - loss: 1.0509\n",
            "Epoch 16/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 1.0129\n",
            "Epoch 17/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 0.9753\n",
            "Epoch 18/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 0.9373\n",
            "Epoch 19/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 0.9006\n",
            "Epoch 20/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 0.8642\n",
            "Epoch 21/40\n",
            "172/172 [==============================] - 15s 89ms/step - loss: 0.8303\n",
            "Epoch 22/40\n",
            "172/172 [==============================] - 15s 89ms/step - loss: 0.7970\n",
            "Epoch 23/40\n",
            "172/172 [==============================] - 15s 89ms/step - loss: 0.7682\n",
            "Epoch 24/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 0.7393\n",
            "Epoch 25/40\n",
            "172/172 [==============================] - 15s 89ms/step - loss: 0.7142\n",
            "Epoch 26/40\n",
            "172/172 [==============================] - 15s 89ms/step - loss: 0.6921\n",
            "Epoch 27/40\n",
            "172/172 [==============================] - 15s 89ms/step - loss: 0.6700\n",
            "Epoch 28/40\n",
            "172/172 [==============================] - 15s 89ms/step - loss: 0.6522\n",
            "Epoch 29/40\n",
            "172/172 [==============================] - 15s 89ms/step - loss: 0.6333\n",
            "Epoch 30/40\n",
            "172/172 [==============================] - 16s 90ms/step - loss: 0.6158\n",
            "Epoch 31/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 0.6013\n",
            "Epoch 32/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 0.5879\n",
            "Epoch 33/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 0.5751\n",
            "Epoch 34/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 0.5615\n",
            "Epoch 35/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 0.5505\n",
            "Epoch 36/40\n",
            "172/172 [==============================] - 16s 90ms/step - loss: 0.5411\n",
            "Epoch 37/40\n",
            "172/172 [==============================] - 16s 90ms/step - loss: 0.5319\n",
            "Epoch 38/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 0.5241\n",
            "Epoch 39/40\n",
            "172/172 [==============================] - 15s 90ms/step - loss: 0.5182\n",
            "Epoch 40/40\n",
            "172/172 [==============================] - 16s 90ms/step - loss: 0.5107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFLGVgUZgC41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rebuild model for predicting\n",
        "\n",
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mckh_y-lgXaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MA2Xr5hgwuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# or load any crappy checkpoint you wnt\n",
        "'''\n",
        "num = 40\n",
        "model.load_weights(tf.train.latest_checkpoint('./training_checkpoints/cpkt_' + str(num)))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaSHAvTzhGTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  num_generate = 800 # predict 800 words\n",
        "\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = 1.0 # low more predictable, high more suprising. Must be optimized\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return(start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5lytp8dirXQ",
        "colab_type": "code",
        "outputId": "d791e114-cbd7-424f-ac92-8d303ac385e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "inp = input('Starting String...')\n",
        "print(generate_text(model, inp))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting String...oh n\n",
            "oh no place herein all this while hath made before,\n",
            "For put it yet, to you, courage, Kate, I will.\n",
            "Father, you'll know more dead or two:\n",
            "I have kill'd King Henry's friendly voice.\n",
            "Yer, first Duke of King Lewis worship,\n",
            "And thy desires the world with the world\n",
            "Marry'd to appear a fortnight shall be my constable.\n",
            "\n",
            "GREMIO:\n",
            "I bray me to my best know her good unnatural\n",
            "countryman.\n",
            "\n",
            "PETRUCHIO:\n",
            "Believe me, thou'rt to crave dwell on my part in home-business,\n",
            "Lest they have put me in your clothes; and here be the faults from some form.\n",
            "\n",
            "CLAUDIO:\n",
            "I have to thee,\n",
            "For 'tis as ever ready to come again.\n",
            "\n",
            "Page:\n",
            "Your Son, the glorious sun to one:\n",
            "This must be so received. Far I not right;\n",
            "Nor need you, gentlemen, adieu.\n",
            "\n",
            "GONZALO:\n",
            "\n",
            "ARILA:\n",
            "Down with the swords and in love is not at the way;\n",
            "Not thus; for Warwic\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}